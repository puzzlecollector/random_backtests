{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import random \n",
    "import os \n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import matplotlib.pyplot as plt \n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import datetime\n",
    "import pybit\n",
    "import ccxt\n",
    "import telegram \n",
    "import math\n",
    "import seaborn as sns\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "### for tabnet ### \n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "### optuna ### \n",
    "import optuna\n",
    "from optuna import Trial, visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "eth2019 = pd.read_csv(\"2019_ETHUSDT.csv\") \n",
    "eth2020 = pd.read_csv(\"2020_ETHUSDT.csv\")  \n",
    "eth2021 = pd.read_csv(\"2021_ETHUSDT.csv\") \n",
    "eth2022 = pd.read_csv(\"2022_ETHUSDT.csv\") \n",
    "\n",
    "df = pd.concat([eth2019,eth2020,eth2021,eth2022], axis=0) \n",
    "df.index = np.arange(df.shape[0]) \n",
    "\n",
    "df = df.drop(columns={'0'})\n",
    "df = df[df['Volume'] > 0] # get rid of rows with zero volume "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_timestamps(df, ccxt_bybit): \n",
    "    dates = df['Open Time'].values \n",
    "    ccxt_bybit = ccxt.bybit() \n",
    "    timestamp = [] \n",
    "    for i in range(len(dates)): \n",
    "        date_string = ccxt_bybit.iso8601(int(dates[i]))  \n",
    "        date_string = date_string[:10] + \" \" + date_string[11:-5] \n",
    "        timestamp.append(date_string)  \n",
    "    df['timestamp'] = timestamp \n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp']) \n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rsi_calc(df, period): \n",
    "    df = df['Close'].astype(float) \n",
    "    delta = df.diff() \n",
    "    gains, declines = delta.copy(), delta.copy() \n",
    "    gains[gains < 0] = 0 \n",
    "    declines[declines > 0] = 0 \n",
    "    _gains = gains.ewm(com=(period-1), min_periods=period).mean() \n",
    "    _loss = declines.abs().ewm(com=(period-1), min_periods=period).mean() \n",
    "    RS = _gains / _loss\n",
    "    return pd.Series((100 - (100 / (1+RS)))/100, name=\"Scaled_RSI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/26857 [00:00<?, ?it/s]/opt/conda/lib/python3.6/site-packages/pandas/core/indexing.py:670: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "100%|██████████| 26857/26857 [10:19<00:00, 43.33it/s]\n",
      "100%|██████████| 26857/26857 [11:27<00:00, 39.09it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hour</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>close_ma5_ratio</th>\n",
       "      <th>volume_ma5_ratio</th>\n",
       "      <th>close_ma10_ratio</th>\n",
       "      <th>volume_ma10_ratio</th>\n",
       "      <th>close_ma20_ratio</th>\n",
       "      <th>volume_ma20_ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>volume_111apartvolume_ratio</th>\n",
       "      <th>volume_112apartvolume_ratio</th>\n",
       "      <th>volume_113apartvolume_ratio</th>\n",
       "      <th>volume_114apartvolume_ratio</th>\n",
       "      <th>volume_115apartvolume_ratio</th>\n",
       "      <th>volume_116apartvolume_ratio</th>\n",
       "      <th>volume_117apartvolume_ratio</th>\n",
       "      <th>volume_118apartvolume_ratio</th>\n",
       "      <th>volume_119apartvolume_ratio</th>\n",
       "      <th>volume_120apartvolume_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.013170</td>\n",
       "      <td>-0.311798</td>\n",
       "      <td>0.033473</td>\n",
       "      <td>-0.090164</td>\n",
       "      <td>0.042926</td>\n",
       "      <td>-0.044944</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.006966</td>\n",
       "      <td>-0.523102</td>\n",
       "      <td>0.027567</td>\n",
       "      <td>-0.400415</td>\n",
       "      <td>0.042274</td>\n",
       "      <td>-0.352542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.003023</td>\n",
       "      <td>-0.478648</td>\n",
       "      <td>0.017314</td>\n",
       "      <td>-0.371902</td>\n",
       "      <td>0.036570</td>\n",
       "      <td>-0.274155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.002034</td>\n",
       "      <td>-0.286171</td>\n",
       "      <td>0.011617</td>\n",
       "      <td>-0.385466</td>\n",
       "      <td>0.034279</td>\n",
       "      <td>-0.273873</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002237</td>\n",
       "      <td>-0.170133</td>\n",
       "      <td>0.011619</td>\n",
       "      <td>-0.470016</td>\n",
       "      <td>0.036758</td>\n",
       "      <td>-0.368733</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 260 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Hour  Day  Month  Weekday  close_ma5_ratio  volume_ma5_ratio  \\\n",
       "99      2    5      1        5         0.013170         -0.311798   \n",
       "100     3    5      1        5         0.006966         -0.523102   \n",
       "101     4    5      1        5        -0.003023         -0.478648   \n",
       "102     4    5      1        5        -0.002034         -0.286171   \n",
       "103     5    5      1        5         0.002237         -0.170133   \n",
       "\n",
       "     close_ma10_ratio  volume_ma10_ratio  close_ma20_ratio  volume_ma20_ratio  \\\n",
       "99           0.033473          -0.090164          0.042926          -0.044944   \n",
       "100          0.027567          -0.400415          0.042274          -0.352542   \n",
       "101          0.017314          -0.371902          0.036570          -0.274155   \n",
       "102          0.011617          -0.385466          0.034279          -0.273873   \n",
       "103          0.011619          -0.470016          0.036758          -0.368733   \n",
       "\n",
       "     ...  volume_111apartvolume_ratio  volume_112apartvolume_ratio  \\\n",
       "99   ...                          0.0                          0.0   \n",
       "100  ...                          0.0                          0.0   \n",
       "101  ...                          0.0                          0.0   \n",
       "102  ...                          0.0                          0.0   \n",
       "103  ...                          0.0                          0.0   \n",
       "\n",
       "     volume_113apartvolume_ratio  volume_114apartvolume_ratio  \\\n",
       "99                           0.0                          0.0   \n",
       "100                          0.0                          0.0   \n",
       "101                          0.0                          0.0   \n",
       "102                          0.0                          0.0   \n",
       "103                          0.0                          0.0   \n",
       "\n",
       "     volume_115apartvolume_ratio  volume_116apartvolume_ratio  \\\n",
       "99                           0.0                          0.0   \n",
       "100                          0.0                          0.0   \n",
       "101                          0.0                          0.0   \n",
       "102                          0.0                          0.0   \n",
       "103                          0.0                          0.0   \n",
       "\n",
       "     volume_117apartvolume_ratio  volume_118apartvolume_ratio  \\\n",
       "99                           0.0                          0.0   \n",
       "100                          0.0                          0.0   \n",
       "101                          0.0                          0.0   \n",
       "102                          0.0                          0.0   \n",
       "103                          0.0                          0.0   \n",
       "\n",
       "     volume_119apartvolume_ratio  volume_120apartvolume_ratio  \n",
       "99                           0.0                          0.0  \n",
       "100                          0.0                          0.0  \n",
       "101                          0.0                          0.0  \n",
       "102                          0.0                          0.0  \n",
       "103                          0.0                          0.0  \n",
       "\n",
       "[5 rows x 260 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_df(df, ccxt_bybit): \n",
    "    df = create_timestamps(df, ccxt_bybit)\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df['Hour'] = df['timestamp'].apply(lambda x: x.hour)\n",
    "    df['Weekday'] = df['timestamp'].apply(lambda x: x.weekday())\n",
    "    df['Day'] = df['timestamp'].apply(lambda x: x.day)\n",
    "    df['Month'] = df['timestamp'].apply(lambda x: x.month)\n",
    "    \n",
    "    df['vwap'] = (df['Volume'] * (df['High'] + df['Low'])/2).cumsum() / df['Volume'].cumsum() \n",
    "    vwap = df['vwap'].values \n",
    "    vwap_ratio = [None] \n",
    "    for i in range(1, len(vwap)): \n",
    "        ratio = vwap[i] / vwap[i-1] \n",
    "        vwap_ratio.append(ratio) \n",
    "    df['vwap_ratio'] = vwap_ratio \n",
    "\n",
    "    df['RSI'] = rsi_calc(df, period=14)\n",
    "    \n",
    "    eps = 1e-10 ### to avoid division by zero for Volume calculations ### \n",
    "    \n",
    "    for window in [5,10,20,30,50,100]: \n",
    "        df['close_ma{}'.format(window)] = df['Close'].rolling(window).mean() \n",
    "        df['volume_ma{}'.format(window)] = df['Volume'].rolling(window).mean()\n",
    "        df['close_ma{}_ratio'.format(window)] = (df['Close'] - df['close_ma{}'.format(window)]) / df['close_ma{}'.format(window)] \n",
    "        df['volume_ma{}_ratio'.format(window)] = (df['Volume'] - df['volume_ma{}'.format(window)]) / (df['volume_ma{}'.format(window)]+eps)\n",
    "    \n",
    "    open_prices = df['Open'].values \n",
    "    close_prices = df['Close'].values \n",
    "    volumes = df['Volume'].values \n",
    "    \n",
    "    ### strides and differencing ###\n",
    "    stride_colnames = [] \n",
    "    strides = 121\n",
    "    for i in range(2, strides): \n",
    "        df['close_{}apartclose_ratio'.format(i)] = np.zeros((df.shape[0])) \n",
    "        stride_colnames.append('close_{}apartclose_ratio'.format(i)) \n",
    "    for i in tqdm(range(strides,df.shape[0]), position=0, leave=True):\n",
    "        ret = [] \n",
    "        for j in range(2,strides):\n",
    "            ratio = close_prices[i] / close_prices[i-j] \n",
    "            df['close_{}apartclose_ratio'.format(j)].iloc[i] = ratio  \n",
    "            \n",
    "    for i in range(2, strides):  \n",
    "        df['volume_{}apartvolume_ratio'.format(i)] = np.zeros((df.shape[0])) \n",
    "        stride_colnames.append('volume_{}apartvolume_ratio'.format(i)) \n",
    "    for i in tqdm(range(strides,df.shape[0]), position=0, leave=True):\n",
    "        ret = [] \n",
    "        for j in range(2,strides): \n",
    "            ratio = volumes[i] / volumes[i-j] \n",
    "            df['volume_{}apartvolume_ratio'.format(j)].iloc[i] = ratio \n",
    "        \n",
    "    labels = [] \n",
    "    for i in range(len(close_prices)-1): \n",
    "        ret = close_prices[i+1] / close_prices[i] \n",
    "        if ret > 1.0:  \n",
    "            labels.append(1) \n",
    "        elif ret <= 1.0: \n",
    "            labels.append(0) \n",
    "    labels.append(None)\n",
    "    df['Labels'] = labels \n",
    "    \n",
    "    df['high_close_ratio'] = (df['High'].values - df['Close'].values) / df['Close'].values \n",
    "    df['low_close_ratio'] = (df['Low'].values - df['Close'].values) / df['Close'].values  \n",
    "    \n",
    "    close_lastclose_ratio = [None] \n",
    "    for i in range(1, len(close_prices)): \n",
    "        ratio = close_prices[i] / close_prices[i-1] \n",
    "        close_lastclose_ratio.append(ratio) \n",
    "    df['close_lastclose_ratio'] = close_lastclose_ratio \n",
    "    \n",
    "    volume_lastvolume_ratio = [None] \n",
    "    for i in range(1, len(volumes)):\n",
    "        ratio = volumes[i] / (volumes[i-1]+eps) \n",
    "        volume_lastvolume_ratio.append(ratio) \n",
    "    df['volume_lastvolume_ratio'] = volume_lastvolume_ratio\n",
    "    \n",
    "    cols = [\"Hour\",\n",
    "            \"Day\", \n",
    "            \"Month\",\n",
    "            \"Weekday\", \n",
    "            \"close_ma5_ratio\", \n",
    "            \"volume_ma5_ratio\",\n",
    "            \"close_ma10_ratio\", \n",
    "            \"volume_ma10_ratio\",\n",
    "            \"close_ma20_ratio\", \n",
    "            \"volume_ma20_ratio\", \n",
    "            \"close_ma30_ratio\", \n",
    "            \"volume_ma30_ratio\", \n",
    "            \"close_ma50_ratio\", \n",
    "            \"volume_ma50_ratio\",\n",
    "            \"close_ma100_ratio\",\n",
    "            \"volume_ma100_ratio\", \n",
    "            \"high_close_ratio\",\n",
    "            \"low_close_ratio\", \n",
    "            \"close_lastclose_ratio\", \n",
    "            \"volume_lastvolume_ratio\",\n",
    "            \"vwap_ratio\", \n",
    "            \"Labels\"] \n",
    "    \n",
    "    cols = cols + stride_colnames \n",
    "    df = df[cols] # specify feature columns  \n",
    "    return df\n",
    "\n",
    "ccxt_bybit = ccxt.bybit() \n",
    "\n",
    "df = preprocess_df(df, ccxt_bybit) \n",
    "\n",
    "df = df.dropna() \n",
    "\n",
    "df.to_csv(\"feature_engineered_larger_ethusdt.csv\",index=False)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"feature_engineered_larger_ethusdt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[22:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns \n",
    "train_cols, targets = [], [] \n",
    "for col in cols: \n",
    "    if col == \"Labels\": \n",
    "        targets.append(col)\n",
    "    else: \n",
    "        train_cols.append(col) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26856, 259), (26856,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[train_cols] \n",
    "Y = df[targets] \n",
    "\n",
    "X = X.values\n",
    "Y = Y.values.reshape((-1)) \n",
    "\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Objective(trial): \n",
    "    mask_type = trial.suggest_categorical('mask_type', [\"entmax\", \"sparsemax\"]) \n",
    "    n_da = trial.suggest_int(\"n_da\", 8, 64, step=4)\n",
    "    n_steps = trial.suggest_int(\"n_steps\", 3, 10, step=1) \n",
    "    gamma = trial.suggest_float(\"gamma\", 1.0, 2.0, step = 0.2) \n",
    "    n_shared = trial.suggest_int(\"n_shared\", 1, 5) \n",
    "    lambda_sparse = trial.suggest_float(\"lambda_sparse\", 1e-6, 1e-3, log=True) \n",
    "    \n",
    "    tabnet_params = dict(n_d = n_da, \n",
    "                         n_a = n_da, \n",
    "                         n_steps = n_steps, \n",
    "                         gamma = gamma, \n",
    "                         lambda_sparse = lambda_sparse, \n",
    "                         optimizer_fn = torch.optim.Adam,\n",
    "                         optimizer_params = dict(lr=2e-2, weight_decay=1e-5), \n",
    "                         mask_type = mask_type,\n",
    "                         n_shared = n_shared, \n",
    "                         scheduler_params = dict(mode=\"min\", \n",
    "                                                 patience = trial.suggest_int(\"patienceScheduler\", low = 3, high = 10),\n",
    "                                                 min_lr = 1e-5,\n",
    "                                                 factor = 0.5),\n",
    "                         scheduler_fn = torch.optim.lr_scheduler.ReduceLROnPlateau, \n",
    "                         verbose = 1) \n",
    "    \n",
    "    \n",
    "    kf = KFold(n_splits = 5, random_state = 42, shuffle = True)\n",
    "    cv_score_array = [] \n",
    "    for (train_idx, val_idx) in kf.split(X): \n",
    "        X_train, X_val = X[train_idx], X[val_idx] \n",
    "        Y_train, Y_val = Y[train_idx], Y[val_idx] \n",
    "        clf = TabNetClassifier(**tabnet_params) \n",
    "        clf.fit(X_train = X_train, \n",
    "                y_train = Y_train, \n",
    "                eval_set = [(X_val, Y_val)], \n",
    "                patience = trial.suggest_int(\"patience\", low=20, high=60), max_epochs = trial.suggest_int('epochs',100,1000), \n",
    "                eval_metric = [\"auc\", \"accuracy\"], \n",
    "                drop_last = True) \n",
    "        cv_score_array.append(clf.best_cost) \n",
    "    avg = np.mean(cv_score_array) \n",
    "    return avg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-10 14:28:08,038]\u001b[0m A new study created in memory with name: TabNet_optimization_clf_2\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n",
      "epoch 0  | loss: 0.92402 | val_0_auc: 0.48995 | val_0_accuracy: 0.50242 |  0:00:08s\n",
      "epoch 1  | loss: 0.71754 | val_0_auc: 0.497   | val_0_accuracy: 0.49721 |  0:00:16s\n",
      "epoch 2  | loss: 0.69343 | val_0_auc: 0.50164 | val_0_accuracy: 0.50354 |  0:00:24s\n",
      "epoch 3  | loss: 0.69425 | val_0_auc: 0.49786 | val_0_accuracy: 0.50112 |  0:00:32s\n",
      "epoch 4  | loss: 0.69174 | val_0_auc: 0.50469 | val_0_accuracy: 0.50335 |  0:00:40s\n",
      "epoch 5  | loss: 0.68944 | val_0_auc: 0.5034  | val_0_accuracy: 0.49814 |  0:00:48s\n",
      "epoch 6  | loss: 0.68927 | val_0_auc: 0.50415 | val_0_accuracy: 0.50819 |  0:00:56s\n",
      "epoch 7  | loss: 0.68867 | val_0_auc: 0.49842 | val_0_accuracy: 0.49684 |  0:01:03s\n",
      "epoch 8  | loss: 0.68765 | val_0_auc: 0.50264 | val_0_accuracy: 0.49274 |  0:01:11s\n",
      "epoch 9  | loss: 0.68707 | val_0_auc: 0.50098 | val_0_accuracy: 0.4959  |  0:01:19s\n",
      "epoch 10 | loss: 0.68687 | val_0_auc: 0.50611 | val_0_accuracy: 0.50633 |  0:01:26s\n",
      "epoch 11 | loss: 0.68622 | val_0_auc: 0.50378 | val_0_accuracy: 0.50261 |  0:01:34s\n",
      "epoch 12 | loss: 0.68774 | val_0_auc: 0.51215 | val_0_accuracy: 0.50428 |  0:01:42s\n",
      "epoch 13 | loss: 0.68642 | val_0_auc: 0.50645 | val_0_accuracy: 0.50205 |  0:01:50s\n",
      "epoch 14 | loss: 0.68646 | val_0_auc: 0.50843 | val_0_accuracy: 0.50112 |  0:01:58s\n",
      "epoch 15 | loss: 0.68573 | val_0_auc: 0.51105 | val_0_accuracy: 0.50577 |  0:02:05s\n",
      "epoch 16 | loss: 0.6856  | val_0_auc: 0.51213 | val_0_accuracy: 0.5041  |  0:02:13s\n",
      "epoch 17 | loss: 0.68492 | val_0_auc: 0.51363 | val_0_accuracy: 0.5108  |  0:02:20s\n",
      "epoch 18 | loss: 0.68503 | val_0_auc: 0.50865 | val_0_accuracy: 0.49758 |  0:02:28s\n",
      "epoch 19 | loss: 0.6839  | val_0_auc: 0.50741 | val_0_accuracy: 0.49963 |  0:02:35s\n",
      "epoch 20 | loss: 0.68458 | val_0_auc: 0.51013 | val_0_accuracy: 0.50279 |  0:02:43s\n",
      "epoch 21 | loss: 0.68429 | val_0_auc: 0.50979 | val_0_accuracy: 0.50112 |  0:02:50s\n",
      "epoch 22 | loss: 0.68345 | val_0_auc: 0.51461 | val_0_accuracy: 0.50503 |  0:02:59s\n",
      "epoch 23 | loss: 0.68387 | val_0_auc: 0.5117  | val_0_accuracy: 0.50298 |  0:03:06s\n",
      "epoch 24 | loss: 0.68341 | val_0_auc: 0.51215 | val_0_accuracy: 0.50112 |  0:03:13s\n",
      "epoch 25 | loss: 0.68265 | val_0_auc: 0.51633 | val_0_accuracy: 0.50428 |  0:03:21s\n",
      "epoch 26 | loss: 0.68281 | val_0_auc: 0.51842 | val_0_accuracy: 0.50894 |  0:03:29s\n",
      "epoch 27 | loss: 0.68259 | val_0_auc: 0.5213  | val_0_accuracy: 0.5108  |  0:03:36s\n",
      "epoch 28 | loss: 0.68249 | val_0_auc: 0.52597 | val_0_accuracy: 0.51638 |  0:03:44s\n",
      "epoch 29 | loss: 0.68213 | val_0_auc: 0.52364 | val_0_accuracy: 0.50949 |  0:03:52s\n",
      "epoch 30 | loss: 0.68245 | val_0_auc: 0.52778 | val_0_accuracy: 0.51843 |  0:03:59s\n",
      "epoch 31 | loss: 0.68243 | val_0_auc: 0.52721 | val_0_accuracy: 0.51564 |  0:04:07s\n",
      "epoch 32 | loss: 0.68198 | val_0_auc: 0.52859 | val_0_accuracy: 0.51806 |  0:04:14s\n",
      "epoch 33 | loss: 0.68202 | val_0_auc: 0.5321  | val_0_accuracy: 0.52383 |  0:04:22s\n",
      "epoch 34 | loss: 0.68149 | val_0_auc: 0.53433 | val_0_accuracy: 0.52513 |  0:04:29s\n",
      "epoch 35 | loss: 0.68159 | val_0_auc: 0.53491 | val_0_accuracy: 0.52625 |  0:04:38s\n",
      "epoch 36 | loss: 0.68186 | val_0_auc: 0.53747 | val_0_accuracy: 0.52606 |  0:04:46s\n",
      "epoch 37 | loss: 0.68187 | val_0_auc: 0.53667 | val_0_accuracy: 0.52792 |  0:04:54s\n",
      "epoch 38 | loss: 0.68203 | val_0_auc: 0.54078 | val_0_accuracy: 0.5296  |  0:05:01s\n",
      "epoch 39 | loss: 0.68143 | val_0_auc: 0.54058 | val_0_accuracy: 0.53034 |  0:05:09s\n",
      "epoch 40 | loss: 0.6818  | val_0_auc: 0.54207 | val_0_accuracy: 0.52885 |  0:05:16s\n",
      "epoch 41 | loss: 0.6821  | val_0_auc: 0.54331 | val_0_accuracy: 0.52829 |  0:05:24s\n",
      "epoch 42 | loss: 0.68122 | val_0_auc: 0.54348 | val_0_accuracy: 0.53053 |  0:05:31s\n",
      "epoch 43 | loss: 0.68176 | val_0_auc: 0.54372 | val_0_accuracy: 0.53016 |  0:05:39s\n",
      "epoch 44 | loss: 0.68178 | val_0_auc: 0.54472 | val_0_accuracy: 0.53295 |  0:05:46s\n",
      "epoch 45 | loss: 0.6814  | val_0_auc: 0.5458  | val_0_accuracy: 0.53462 |  0:05:54s\n",
      "epoch 46 | loss: 0.68151 | val_0_auc: 0.54689 | val_0_accuracy: 0.535   |  0:06:01s\n",
      "epoch 47 | loss: 0.68059 | val_0_auc: 0.54739 | val_0_accuracy: 0.53462 |  0:06:09s\n",
      "epoch 48 | loss: 0.68102 | val_0_auc: 0.5472  | val_0_accuracy: 0.53555 |  0:06:16s\n",
      "epoch 49 | loss: 0.68066 | val_0_auc: 0.54792 | val_0_accuracy: 0.53723 |  0:06:24s\n",
      "epoch 50 | loss: 0.68156 | val_0_auc: 0.54843 | val_0_accuracy: 0.53816 |  0:06:32s\n",
      "epoch 51 | loss: 0.68159 | val_0_auc: 0.54823 | val_0_accuracy: 0.5376  |  0:06:39s\n",
      "epoch 52 | loss: 0.6813  | val_0_auc: 0.54906 | val_0_accuracy: 0.53891 |  0:06:46s\n",
      "epoch 53 | loss: 0.68097 | val_0_auc: 0.54762 | val_0_accuracy: 0.53611 |  0:06:54s\n",
      "epoch 54 | loss: 0.68129 | val_0_auc: 0.54912 | val_0_accuracy: 0.53574 |  0:07:01s\n",
      "epoch 55 | loss: 0.68141 | val_0_auc: 0.54935 | val_0_accuracy: 0.53593 |  0:07:10s\n",
      "epoch 56 | loss: 0.68129 | val_0_auc: 0.54949 | val_0_accuracy: 0.53797 |  0:07:18s\n",
      "epoch 57 | loss: 0.68146 | val_0_auc: 0.54894 | val_0_accuracy: 0.5363  |  0:07:26s\n",
      "epoch 58 | loss: 0.68193 | val_0_auc: 0.54908 | val_0_accuracy: 0.53835 |  0:07:34s\n",
      "epoch 59 | loss: 0.68097 | val_0_auc: 0.54871 | val_0_accuracy: 0.53723 |  0:07:42s\n",
      "epoch 60 | loss: 0.68121 | val_0_auc: 0.54911 | val_0_accuracy: 0.5363  |  0:07:49s\n",
      "epoch 61 | loss: 0.68106 | val_0_auc: 0.54899 | val_0_accuracy: 0.53816 |  0:07:57s\n",
      "epoch 62 | loss: 0.68112 | val_0_auc: 0.54909 | val_0_accuracy: 0.53797 |  0:08:04s\n",
      "epoch 63 | loss: 0.68171 | val_0_auc: 0.54953 | val_0_accuracy: 0.53593 |  0:08:12s\n",
      "epoch 64 | loss: 0.6818  | val_0_auc: 0.54986 | val_0_accuracy: 0.53704 |  0:08:20s\n",
      "epoch 65 | loss: 0.68112 | val_0_auc: 0.54899 | val_0_accuracy: 0.53779 |  0:08:28s\n",
      "epoch 66 | loss: 0.68109 | val_0_auc: 0.54908 | val_0_accuracy: 0.53742 |  0:08:35s\n",
      "epoch 67 | loss: 0.68089 | val_0_auc: 0.54887 | val_0_accuracy: 0.53742 |  0:08:43s\n",
      "epoch 68 | loss: 0.68086 | val_0_auc: 0.54972 | val_0_accuracy: 0.53518 |  0:08:51s\n",
      "epoch 69 | loss: 0.68156 | val_0_auc: 0.54967 | val_0_accuracy: 0.5376  |  0:08:58s\n",
      "epoch 70 | loss: 0.68101 | val_0_auc: 0.54905 | val_0_accuracy: 0.5376  |  0:09:05s\n",
      "epoch 71 | loss: 0.68151 | val_0_auc: 0.54954 | val_0_accuracy: 0.53853 |  0:09:13s\n",
      "epoch 72 | loss: 0.68118 | val_0_auc: 0.5492  | val_0_accuracy: 0.53779 |  0:09:20s\n",
      "epoch 73 | loss: 0.68136 | val_0_auc: 0.5498  | val_0_accuracy: 0.53872 |  0:09:28s\n",
      "epoch 74 | loss: 0.68084 | val_0_auc: 0.5495  | val_0_accuracy: 0.53853 |  0:09:37s\n",
      "epoch 75 | loss: 0.68134 | val_0_auc: 0.54906 | val_0_accuracy: 0.53742 |  0:09:44s\n",
      "epoch 76 | loss: 0.68131 | val_0_auc: 0.54889 | val_0_accuracy: 0.53649 |  0:09:51s\n",
      "epoch 77 | loss: 0.68101 | val_0_auc: 0.54953 | val_0_accuracy: 0.53686 |  0:09:59s\n",
      "epoch 78 | loss: 0.68092 | val_0_auc: 0.54958 | val_0_accuracy: 0.53649 |  0:10:06s\n",
      "epoch 79 | loss: 0.68083 | val_0_auc: 0.54966 | val_0_accuracy: 0.53835 |  0:10:15s\n",
      "epoch 80 | loss: 0.68089 | val_0_auc: 0.54943 | val_0_accuracy: 0.53742 |  0:10:23s\n",
      "epoch 81 | loss: 0.68131 | val_0_auc: 0.54882 | val_0_accuracy: 0.53816 |  0:10:31s\n",
      "epoch 82 | loss: 0.68068 | val_0_auc: 0.54883 | val_0_accuracy: 0.53537 |  0:10:39s\n",
      "epoch 83 | loss: 0.68113 | val_0_auc: 0.5496  | val_0_accuracy: 0.53797 |  0:10:46s\n",
      "epoch 84 | loss: 0.68197 | val_0_auc: 0.54955 | val_0_accuracy: 0.535   |  0:10:54s\n",
      "epoch 85 | loss: 0.68133 | val_0_auc: 0.54951 | val_0_accuracy: 0.53667 |  0:11:01s\n",
      "epoch 86 | loss: 0.68076 | val_0_auc: 0.54988 | val_0_accuracy: 0.53853 |  0:11:09s\n",
      "epoch 87 | loss: 0.68074 | val_0_auc: 0.54962 | val_0_accuracy: 0.53853 |  0:11:16s\n",
      "epoch 88 | loss: 0.68064 | val_0_auc: 0.55018 | val_0_accuracy: 0.53928 |  0:11:24s\n",
      "epoch 89 | loss: 0.6805  | val_0_auc: 0.54937 | val_0_accuracy: 0.53723 |  0:11:31s\n",
      "epoch 90 | loss: 0.68185 | val_0_auc: 0.54911 | val_0_accuracy: 0.53518 |  0:11:39s\n",
      "epoch 91 | loss: 0.6808  | val_0_auc: 0.5494  | val_0_accuracy: 0.53742 |  0:11:47s\n",
      "epoch 92 | loss: 0.68132 | val_0_auc: 0.54968 | val_0_accuracy: 0.53816 |  0:11:55s\n",
      "epoch 93 | loss: 0.68046 | val_0_auc: 0.54957 | val_0_accuracy: 0.53555 |  0:12:03s\n",
      "epoch 94 | loss: 0.68117 | val_0_auc: 0.54886 | val_0_accuracy: 0.53704 |  0:12:11s\n",
      "epoch 95 | loss: 0.68104 | val_0_auc: 0.54914 | val_0_accuracy: 0.53704 |  0:12:19s\n",
      "epoch 96 | loss: 0.68096 | val_0_auc: 0.54961 | val_0_accuracy: 0.53853 |  0:12:27s\n",
      "epoch 97 | loss: 0.68122 | val_0_auc: 0.54919 | val_0_accuracy: 0.53835 |  0:12:35s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98 | loss: 0.68108 | val_0_auc: 0.54937 | val_0_accuracy: 0.53816 |  0:12:42s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-1fd0a5a9c85a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"maximize\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"TabNet_optimization_clf_2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mObjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         )\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-a421c0f652ee>\u001b[0m in \u001b[0;36mObjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mpatience\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"patience\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0meval_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"auc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                 drop_last = True) \n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mcv_score_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_cost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mavg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_score_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pytorch_tabnet/abstract_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train, eval_set, eval_name, eval_metric, loss_fn, weights, max_epochs, patience, batch_size, virtual_batch_size, num_workers, drop_last, callbacks, pin_memory, from_unsupervised)\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callback_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0;31m# Apply predict epoch to all eval sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pytorch_tabnet/abstract_model.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, train_loader)\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callback_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callback_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pytorch_tabnet/abstract_model.py\u001b[0m in \u001b[0;36m_train_batch\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;31m# Perform backward pass and optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction = \"maximize\", study_name = \"TabNet_optimization_clf_2\") \n",
    "\n",
    "study.optimize(Objective, timeout = 6*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TabNet_params = study.best_params \n",
    "TabNet_params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24170, 259), (2686, 259), (24170,), (2686,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size = 0.1, random_state = 888) \n",
    "\n",
    "X_train.shape, X_val.shape, Y_train.shape, Y_val.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
